# Plastic Detection AI

## Overview

This project focuses on developing an AI model capable of detecting plastic items in real-time using advanced computer vision techniques. The core model is built on **YOLOv5** (You Only Look Once), a state-of-the-art object detection framework. By automating plastic detection, the project aims to address environmental challenges such as waste management and recycling inefficiencies.

The initial experiment (Exp1) uses a custom dataset of plastic items, with images and annotations provided in the `data/train` folder. This dataset enables the AI model to learn and effectively identify plastic items under varying conditions.

---

## How It Works

1. **Dataset**: 
   - The dataset is located in the `data/train` folder.
   - It consists of labeled images of plastic items captured in diverse environments, ensuring robust detection across real-world scenarios.

2. **Model Architecture**:
   - YOLOv5 is employed for its high speed and accuracy.
   - It is ideal for detecting plastic items in real-time applications like recycling plants or waste sorting systems.

3. **Training**:
   - The model is trained on labeled images, which include bounding boxes around plastic items.
   - Through this training, the AI learns to recognize plastic items in complex scenes.

4. **Inference**:
   - The trained model can detect plastic items in live video streams or static images.
   - It outputs bounding boxes, class names, and confidence scores, enabling real-time applications.

---

## Installation and Running the Detection

To set up and run the project, follow these steps:

# Step 1: Clone the repository
```bash
git clone <repository-url>
```

# Step 2: Install the dependencies
```bash
pip install -r requirements.txt
```

# Step 3: Download YOLOv5 weights
  The trained weights (best.pt) are located in the 'runs/train' folder
  or can be generated by training the model.

# Step 4: Train the model
```bash
python train.py --data data.yaml --cfg models/yolov5s.yaml --weights yolov5s.pt --epochs 100
```
# Step 5: Run inference
```
python detect.py --source <video_or_image_path> --weights runs/train/best.pt
```
# Results
In the initial experiment (Exp1), the model achieved:

Accuracy: 94%
Precision: 89%

These results demonstrate that the model can reliably detect plastic items, even in challenging conditions.

# Future Work
Expand the dataset to include a wider variety of plastic types and environments.
Integrate the AI into recycling lines for real-time sorting and waste management.
Develop an edge AI system for deployment in low-resource environments.

# License
This project is licensed under the MIT License. See the LICENSE file for details.
